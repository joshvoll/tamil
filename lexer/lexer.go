package lexer

import "go/token"

// Lexer definition
type Lexer struct {
	input        string
	position     int  // current position in input (points to current chararacter)
	readPosition int  // current reading position in input (after current chararacter)
	ch           byte // current char under examination
}

// New contructor function
func New(input string) *Lexer {
	l := &Lexer{
		input: input,
	}
	l.readChar()
	return l
}

// readChar is going to give us the next character and advance our position in the input string
// The first thing it does is to check whether we have reached the end of input
// If that’s the case it sets l.ch to 0, which is the ASCII code for the "NUL"
// character and signifies either “we haven’t read anything yet” or “end of file” for us
// But if we haven’t reached the end of input yet it sets l.ch to the next character
// by accessing l.input[l.readPosition]
func (l *Lexer) readChar() {
	if l.readPosition >= len(l.input) {
		l.ch = 0
	} else {
		l.ch = l.input[l.readPosition]
	}
	l.position = l.readPosition
	l.readPosition++
}

// NextToken is going to get the next token from each sentence
// We look at the current character under examination (l.ch)
// and return a token depending on which character it is
// What our lexer needs to do is recognize
// whether the current character is a letter and if so
func (l *Lexer) NextToken() token.Token {
	var tok token.Token

	l.readChar()
	return tok
}

// readIdentifier helper
// it needs to read the rest of the identifier/keyword until it encounters a non-letter-character
// Having read that identifier/keyword, we then need to find out if it is a identifier or a keyword

// peekChar is going to pick a character from the input but without incrementing the read
// We only want to “peek” ahead in the input and not move around in it
